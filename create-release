#!/bin/sh
set -e

if [ -z "$1" -o -z "$2" ]; then
  echo "Usage: $0 RELEASE-NAME CHART_DIR [helm-args]" >&2
  echo "e.g.: $0 myapp /myapp/deploy/chart/ -f "values-${CI_ENVIRONMENT_SLUG:-prd}.yml" --set="imageTag=${CI_IMAGE_TAG:-1.0}",nameOverride=\$CI_ENVIRONMENT_SLUG"
  exit 1
fi

KUBE_NAMESPACE="${KUBE_NAMESPACE:-default}"

# Automatically use a namespace-based tiller if available,
# or the cluster-wide installed version if this is possible.
if [ -z "$TILLER_NAMESPACE" ]; then
  if [ "$(kubectl auth can-i create pods --subresource=portforward --namespace=kube-system)" = "yes" ]; then
    # Can connect with central installed Tiller, use it to deploy the project
    # Note this could mean that deployments have full cluster-admin access!
    TILLER_NAMESPACE="${TILLER_NAMESPACE:-kube-system}"
    echo "Found cluster-wide tiller installation"
  elif [ "$(kubectl auth can-i create pods --subresource=portforward --namespace=$NAMESPACE)" = "yes" ]; then
    # Can connect with namespace based Tiller
    TILLER_NAMESPACE="${TILLER_NAMESPACE:-$KUBE_NAMESPACE}"
  else
    echo "No RBAC permission to contact to tiller in either 'kube-system' or '$NAMESPACE'" >&2
    exit 1
  fi
fi

echo "Using tiller in namespace $TILLER_NAMESPACE"

# Follow the app=$CI_ENVIRONMENT_SLUG label that GitLab needs to link releases
# helm init --client-only is only needed when using default charts
helm upgrade --install --tiller-namespace "$TILLER_NAMESPACE" --namespace "$KUBE_NAMESPACE" --reset-values --set="nameOverride=$CI_ENVIRONMENT_SLUG" "$@"
echo
echo "Follow the release status using:"
echo
echo "  helm status --tiller-namespace=$TILLER_NAMESPACE $1"
